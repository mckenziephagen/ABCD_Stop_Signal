{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob \n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import chardet \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SST_filepath = '../../SST_Data/recc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = list(set([i.split('-')[1].split('/')[0] for i in glob(SST_file_path + '/sub-*/ses-baselineYear1Arm1/func/*SST*')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_event = []\n",
    "event_files = []\n",
    "for sub in subs: \n",
    "        file = glob(f'../../SST_data/recc/sub-{sub}/ses-baselineYear1Arm1/func/*SST*')\n",
    "       # file = glob(f'../../SST_data/recc/sub-NDAR{sub}/ses-baselineYear1Arm1/func/*SST*')\n",
    "        if len(file) > 0: \n",
    "            event_files.append(str(file[0]))\n",
    "        else: \n",
    "            no_event.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.option_context('display.max_rows', 999)\n",
    "pd.options.display.max_rows = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoding(file): \n",
    "    \"\"\"\n",
    "    retrieves character encoding of file to be passed to \n",
    "    pd.read_csv()\n",
    "    \"\"\"\n",
    "    with open(file, mode = \"rb\") as f: \n",
    "        rawdata = f.read()\n",
    "        return chardet.detect(rawdata)['encoding']\n",
    "    \n",
    "def Diff(li1, li2):\n",
    "    \"\"\"\n",
    "    returns differenes in two lists, from geeks 4 geeks \n",
    "    \"\"\"\n",
    "    return (list(set(li1) - set(li2))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the files sometimes have odd encoding, or an extra column or two or three, requiring some nested try/except syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas.io.parsers import ParserError\n",
    "\n",
    "dfp = []\n",
    "for file in event_files: \n",
    "        encoding = get_encoding(file)\n",
    "        if file[-3:] == 'txt': #this could be put in a function to be neater\n",
    "            try: \n",
    "                df = pd.read_csv(file, sep = '\\t', encoding = encoding)\n",
    "                if df.columns[0] != 'ExperimentName': #to fix header differences\n",
    "                     df = pd.read_csv(file, sep = '\\t', skiprows=[0], encoding = encoding)\n",
    "            except: \n",
    "                try: \n",
    "                    df = pd.read_csv(file, sep = '\\t', skiprows=[0,1], encoding = encoding)\n",
    "                except: \n",
    "            #these files specifically are encoded oddly\n",
    "            if file == '../../SST_data/recc/sub-NDARINVB1CK69PR/ses-baselineYear1Arm1/func/ABCD-SST-fMRI_run-20161105142951-EventRelatedInformation.txt' \\\n",
    "            or file == '../../SST_data/recc/sub-NDARINVB1CK69PR/ses-baselineYear1Arm1/func/ABCD-SST-fMRI_run-20161105142323-EventRelatedInformation.txt':  \n",
    "                df = pd.read_csv(file, sep = '\\t', skiprows=[0,1,2], encoding = encoding)\n",
    "\n",
    "        elif file[-3:] == 'csv': \n",
    "            df = pd.read_csv(file, encoding = encoding)\n",
    "            if df.columns[0] != 'ExperimentName': \n",
    "                df = pd.read_csv(file, encoding = encoding, skiprows=[0])\n",
    "                if len(df.columns) == 1:\n",
    "                    try: \n",
    "                        df = pd.read_csv(file, encoding = encoding, skiprows=[0], sep='\\t')\n",
    "                    except ParserError: \n",
    "                        print(event_file)\n",
    "\n",
    "                    \n",
    "        dfp.append(df)\n",
    "print(\"concatting files together\") \n",
    "event_df = pd.concat(dfp, sort=True, axis = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get rid of all of the non-SST files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(event_df['NARGUID'].loc[event_df['ExperimentName'] == 'MID_20171130'].unique()))\n",
    "event_df = event_df.loc[~(event_df['ExperimentName'] == 'MID_20171130')] \n",
    "\n",
    "print(len(event_df['NARGUID'].loc[event_df['ExperimentName'] == 'MID_20161218'].unique()))\n",
    "event_df = event_df.loc[~(event_df['ExperimentName'] == 'MID_20161218')]\n",
    "\n",
    "print(len(event_df['NARGUID'].loc[(event_df['ExperimentName'] == 'ABCD_SST_Practice_CDbox_20160729')].unique())) #these will need to be counted\n",
    "event_df = event_df.loc[~(event_df['ExperimentName'] == 'ABCD_SST_Practice_CDbox_20160729')] #these will need to be counted\n",
    "\n",
    "event_df = event_df.dropna(axis = 1, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get rid of cluttery columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in event_df.columns:\n",
    "    if 'Unnamed' in col or 'task' in col or 'Test' in col or 'Wait' in col or 'Session' in col or 'Run' in col or 'VARIABLE' in col:\n",
    "        del event_df[col] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_df.to_csv('raw_concat_jan14.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, go to clean_SST and run raw_concat through that for further processing. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
